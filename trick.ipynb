{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPR Hyperbola Detection with YOLOv8 and GAN Augmentation\n",
        "\n",
        "This notebook implements YOLOv8 for Ground Penetrating Radar (GPR) hyperbola detection with optional GAN-based data augmentation.\n",
        "\n",
        "**Setup Instructions:**\n",
        "- Enable GPU: Runtime → Change runtime type → Hardware accelerator → GPU\n",
        "- Uses Colab's built-in PyTorch (no torch install needed)\n",
        "- Pipeline: dataset → GAN augmentation (optional) → conversion → train → evaluate → predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip -q install ultralytics opencv-python numpy tqdm matplotlib Pillow\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download GPR dataset\n",
        "!mkdir -p /content/data\n",
        "!test -d /content/data/gpr-data-classifier || git clone https://github.com/irenexychen/gpr-data-classifier /content/data/gpr-data-classifier\n",
        "\n",
        "# Check dataset structure\n",
        "!ls -la /content/data/gpr-data-classifier\n",
        "!echo \"\\nImages directory:\"\n",
        "!ls /content/data/gpr-data-classifier/images | head -5\n",
        "!echo \"\\nAnnotations directory:\"\n",
        "!ls /content/data/gpr-data-classifier/hyperbola-classifier/annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. GAN Configuration and Implementation (Optional Data Augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GAN Configuration\n",
        "class GANConfig:\n",
        "    # Training parameters\n",
        "    EPOCHS = 500  # Reduced for faster training in Colab\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 0.0002\n",
        "    BETA1 = 0.5\n",
        "    BETA2 = 0.999\n",
        "    \n",
        "    # Image parameters\n",
        "    IMAGE_SIZE = 128  # 128x128 images\n",
        "    CHANNELS = 3      # RGB\n",
        "    \n",
        "    # Generator parameters\n",
        "    Z_DIM = 100       # Noise dimension\n",
        "    G_FEATURES = 64   # Generator feature map size\n",
        "    \n",
        "    # Discriminator parameters\n",
        "    D_FEATURES = 64   # Discriminator feature map size\n",
        "    \n",
        "    # Generation parameters\n",
        "    NUM_GENERATE = 500  # Number of synthetic images to generate\n",
        "    SAVE_INTERVAL = 50  # Save sample images every N epochs\n",
        "\n",
        "print(\"GAN Configuration loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Dataset for GPR Images\n",
        "class GPRDataset(Dataset):\n",
        "    def __init__(self, images_dir, transform=None):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.image_paths = []\n",
        "        \n",
        "        # Collect all image files\n",
        "        for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
        "            self.image_paths.extend(list(self.images_dir.glob(ext)))\n",
        "        \n",
        "        self.transform = transform\n",
        "        print(f\"Found {len(self.image_paths)} images in {images_dir}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image\n",
        "\n",
        "# Data transforms for GPR images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((GANConfig.IMAGE_SIZE, GANConfig.IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "print(\"Dataset class and transforms defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generator Network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=GANConfig.Z_DIM, channels=GANConfig.CHANNELS, features=GANConfig.G_FEATURES):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (batch_size, z_dim, 1, 1)\n",
        "            # First layer: z_dim -> features*16, 4x4\n",
        "            nn.ConvTranspose2d(z_dim, features * 16, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(features * 16),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            # Second layer: features*16 -> features*8, 8x8\n",
        "            nn.ConvTranspose2d(features * 16, features * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 8),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            # Third layer: features*8 -> features*4, 16x16\n",
        "            nn.ConvTranspose2d(features * 8, features * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 4),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            # Fourth layer: features*4 -> features*2, 32x32\n",
        "            nn.ConvTranspose2d(features * 4, features * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 2),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            # Fifth layer: features*2 -> features, 64x64\n",
        "            nn.ConvTranspose2d(features * 2, features, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            # Final layer: features -> channels, 128x128\n",
        "            nn.ConvTranspose2d(features, channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh()  # Output in range [-1, 1]\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Discriminator Network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels=GANConfig.CHANNELS, features=GANConfig.D_FEATURES):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (batch_size, channels, 128, 128)\n",
        "            nn.Conv2d(channels, features, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(features, features * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(features * 2, features * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(features * 4, features * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(features * 8, features * 16, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(features * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(features * 16, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1, 1).squeeze(1)\n",
        "\n",
        "print(\"Generator and Discriminator networks defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility functions for GAN training\n",
        "def weights_init(m):\n",
        "    \"\"\"Initialize network weights\"\"\"\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "def denormalize(tensor):\n",
        "    \"\"\"Convert tensor from [-1, 1] to [0, 1] for visualization\"\"\"\n",
        "    return (tensor + 1) / 2\n",
        "\n",
        "def save_sample_images(generator, epoch, device, num_samples=16):\n",
        "    \"\"\"Save sample generated images\"\"\"\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(num_samples, GANConfig.Z_DIM, 1, 1, device=device)\n",
        "        fake_images = generator(noise)\n",
        "        fake_images = denormalize(fake_images)\n",
        "        \n",
        "        # Create grid\n",
        "        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "        for i, ax in enumerate(axes.flat):\n",
        "            if i < num_samples:\n",
        "                img = fake_images[i].cpu().permute(1, 2, 0)\n",
        "                ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "        \n",
        "        plt.suptitle(f'Generated Images - Epoch {epoch}')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    generator.train()\n",
        "\n",
        "print(\"Utility functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GAN Training Function\n",
        "def train_gan():\n",
        "    \"\"\"Train GAN on GPR dataset\"\"\"\n",
        "    # Load dataset\n",
        "    print(\"Loading GPR dataset...\")\n",
        "    dataset = GPRDataset('/content/data/gpr-data-classifier/images', transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=GANConfig.BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    \n",
        "    # Initialize networks\n",
        "    print(\"Initializing networks...\")\n",
        "    generator = Generator().to(device)\n",
        "    discriminator = Discriminator().to(device)\n",
        "    \n",
        "    # Apply weight initialization\n",
        "    generator.apply(weights_init)\n",
        "    discriminator.apply(weights_init)\n",
        "    \n",
        "    # Setup optimizers\n",
        "    opt_G = optim.Adam(generator.parameters(), lr=GANConfig.LEARNING_RATE, \n",
        "                       betas=(GANConfig.BETA1, GANConfig.BETA2))\n",
        "    opt_D = optim.Adam(discriminator.parameters(), lr=GANConfig.LEARNING_RATE, \n",
        "                       betas=(GANConfig.BETA1, GANConfig.BETA2))\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    # Training loop\n",
        "    print(f\"Starting GAN training for {GANConfig.EPOCHS} epochs...\")\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "    \n",
        "    for epoch in range(GANConfig.EPOCHS):\n",
        "        for i, real_images in enumerate(dataloader):\n",
        "            batch_size = real_images.size(0)\n",
        "            real_images = real_images.to(device)\n",
        "            \n",
        "            # Labels\n",
        "            real_labels = torch.ones(batch_size, device=device)\n",
        "            fake_labels = torch.zeros(batch_size, device=device)\n",
        "            \n",
        "            # Train Discriminator\n",
        "            opt_D.zero_grad()\n",
        "            \n",
        "            # Real images\n",
        "            output_real = discriminator(real_images)\n",
        "            loss_D_real = criterion(output_real, real_labels)\n",
        "            \n",
        "            # Fake images\n",
        "            noise = torch.randn(batch_size, GANConfig.Z_DIM, 1, 1, device=device)\n",
        "            fake_images = generator(noise)\n",
        "            output_fake = discriminator(fake_images.detach())\n",
        "            loss_D_fake = criterion(output_fake, fake_labels)\n",
        "            \n",
        "            # Total discriminator loss\n",
        "            loss_D = loss_D_real + loss_D_fake\n",
        "            loss_D.backward()\n",
        "            opt_D.step()\n",
        "            \n",
        "            # Train Generator\n",
        "            opt_G.zero_grad()\n",
        "            output_fake = discriminator(fake_images)\n",
        "            loss_G = criterion(output_fake, real_labels)  # Generator wants to fool discriminator\n",
        "            loss_G.backward()\n",
        "            opt_G.step()\n",
        "        \n",
        "        # Print progress\n",
        "        if epoch % 20 == 0 or epoch == GANConfig.EPOCHS - 1:\n",
        "            print(f'Epoch [{epoch}/{GANConfig.EPOCHS}] | Loss_D: {loss_D.item():.4f} | Loss_G: {loss_G.item():.4f}')\n",
        "        \n",
        "        # Save sample images\n",
        "        if epoch % GANConfig.SAVE_INTERVAL == 0 or epoch == GANConfig.EPOCHS - 1:\n",
        "            save_sample_images(generator, epoch, device)\n",
        "    \n",
        "    print(\"GAN training completed!\")\n",
        "    return generator, discriminator\n",
        "\n",
        "print(\"GAN training function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic images and create augmented dataset\n",
        "def generate_synthetic_images(generator, num_images=GANConfig.NUM_GENERATE):\n",
        "    \"\"\"Generate synthetic GPR images and save them\"\"\"\n",
        "    generator.eval()\n",
        "    \n",
        "    # Create directory for synthetic images\n",
        "    synthetic_dir = Path('/content/data/gpr-data-classifier/synthetic_images')\n",
        "    synthetic_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    print(f\"Generating {num_images} synthetic GPR images...\")\n",
        "    \n",
        "    generated_count = 0\n",
        "    batch_size = 32  # Generate in batches to avoid memory issues\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        while generated_count < num_images:\n",
        "            current_batch_size = min(batch_size, num_images - generated_count)\n",
        "            \n",
        "            # Generate noise and images\n",
        "            noise = torch.randn(current_batch_size, GANConfig.Z_DIM, 1, 1, device=device)\n",
        "            fake_images = generator(noise)\n",
        "            fake_images = denormalize(fake_images)  # Convert to [0, 1]\n",
        "            \n",
        "            # Save images\n",
        "            for i in range(current_batch_size):\n",
        "                img_tensor = fake_images[i].cpu()\n",
        "                img_array = (img_tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
        "                img_pil = Image.fromarray(img_array)\n",
        "                \n",
        "                img_path = synthetic_dir / f'synthetic_gpr_{generated_count:04d}.jpg'\n",
        "                img_pil.save(img_path, quality=95)\n",
        "                generated_count += 1\n",
        "            \n",
        "            if generated_count % 50 == 0:\n",
        "                print(f\"Generated {generated_count}/{num_images} images...\")\n",
        "    \n",
        "    print(f\"Successfully generated {num_images} synthetic images!\")\n",
        "    print(f\"Saved to: {synthetic_dir}\")\n",
        "    \n",
        "    return synthetic_dir\n",
        "\n",
        "def create_augmented_dataset():\n",
        "    \"\"\"Create augmented dataset combining original and synthetic images\"\"\"\n",
        "    original_images_dir = Path('/content/data/gpr-data-classifier/images')\n",
        "    \n",
        "    # Count original images\n",
        "    original_count = len(list(original_images_dir.glob('*.jpg'))) + \\\n",
        "                    len(list(original_images_dir.glob('*.jpeg'))) + \\\n",
        "                    len(list(original_images_dir.glob('*.png')))\n",
        "    \n",
        "    print(f\"Original dataset size: {original_count} images\")\n",
        "    \n",
        "    # Generate synthetic images if GAN was trained\n",
        "    if 'trained_generator' in globals():\n",
        "        synthetic_dir = generate_synthetic_images(trained_generator)\n",
        "        synthetic_count = len(list(synthetic_dir.glob('*.jpg')))\n",
        "        print(f\"Added {synthetic_count} synthetic images\")\n",
        "        print(f\"Total augmented dataset size: {original_count + synthetic_count} images\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"No trained generator available. Using original dataset only.\")\n",
        "        return False\n",
        "\n",
        "print(\"Synthetic image generation functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GAN Training Control\n",
        "# Set to True to enable GAN training, False to skip\n",
        "train_gan_flag = True\n",
        "\n",
        "print(\"\\n=== GAN Training Instructions ===\")\n",
        "print(\"• Set train_gan_flag = True to enable GAN training (recommended)\")\n",
        "print(\"• Set train_gan_flag = False to skip GAN training if short on time/resources\")\n",
        "print(\"• Training takes approximately 30-60 minutes on T4 GPU with 500 epochs\")\n",
        "print(\"• Generates 500 synthetic GPR images by default\")\n",
        "print(\"• Expected improvements: 2-5% mAP boost, 3.9x larger dataset\")\n",
        "print(f\"\\nCurrent setting: train_gan_flag = {train_gan_flag}\")\n",
        "\n",
        "if train_gan_flag:\n",
        "    print(\"\\nStarting GAN training...\")\n",
        "    trained_generator, trained_discriminator = train_gan()\n",
        "    \n",
        "    # Create augmented dataset\n",
        "    augmentation_success = create_augmented_dataset()\n",
        "else:\n",
        "    print(\"\\nSkipping GAN training. Set train_gan_flag=True to enable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Convert Dataset from VOC to YOLO Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset conversion utilities\n",
        "def read_label_map(label_map_path: Path):\n",
        "    \"\"\"Read class names from label map file\"\"\"\n",
        "    if not label_map_path.exists():\n",
        "        return [\"hyperbola\"]\n",
        "    \n",
        "    text = label_map_path.read_text()\n",
        "    names = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"name:\"):\n",
        "            names.append(line.split(\":\", 1)[1].strip().strip('\\'\"'))\n",
        "    \n",
        "    return names or [\"hyperbola\"]\n",
        "\n",
        "def convert_voc_box_to_yolo(bbox, img_w, img_h):\n",
        "    \"\"\"Convert VOC bounding box to YOLO format\"\"\"\n",
        "    xmin, ymin, xmax, ymax = bbox\n",
        "    xmin = max(0, xmin - 1)\n",
        "    ymin = max(0, ymin - 1)\n",
        "    xmax = min(img_w - 1, xmax - 1)\n",
        "    ymax = min(img_h - 1, ymax - 1)\n",
        "    \n",
        "    bw = xmax - xmin\n",
        "    bh = ymax - ymin\n",
        "    cx = xmin + bw / 2.0\n",
        "    cy = ymin + bh / 2.0\n",
        "    \n",
        "    return (cx / img_w if img_w > 0 else 0.0,\n",
        "            cy / img_h if img_h > 0 else 0.0,\n",
        "            bw / img_w if img_w > 0 else 0.0,\n",
        "            bh / img_h if img_h > 0 else 0.0)\n",
        "\n",
        "def parse_voc_xml(xml_path: Path):\n",
        "    \"\"\"Parse VOC XML annotation file\"\"\"\n",
        "    root = ET.parse(str(xml_path)).getroot()\n",
        "    size = root.find(\"size\")\n",
        "    img_w = int(size.find(\"width\").text)\n",
        "    img_h = int(size.find(\"height\").text)\n",
        "    \n",
        "    objects = []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bnd = obj.find(\"bndbox\")\n",
        "        xmin = int(float(bnd.find(\"xmin\").text))\n",
        "        ymin = int(float(bnd.find(\"ymin\").text))\n",
        "        xmax = int(float(bnd.find(\"xmax\").text))\n",
        "        ymax = int(float(bnd.find(\"ymax\").text))\n",
        "        objects.append((name, (xmin, ymin, xmax, ymax)))\n",
        "    \n",
        "    return img_w, img_h, objects\n",
        "\n",
        "def ensure_dirs(paths):\n",
        "    \"\"\"Create directories if they don't exist\"\"\"\n",
        "    for p in paths:\n",
        "        Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_dataset_yaml(output_root: Path, dataset_name: str, names: list):\n",
        "    \"\"\"Create YOLO dataset YAML file\"\"\"\n",
        "    yaml_path = output_root / f\"{dataset_name}.yaml\"\n",
        "    yaml_content = f\"\"\"path
