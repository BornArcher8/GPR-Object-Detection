{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPR Hyperbola Detection with YOLOv8 (Colab-ready)\n",
        "\n",
        "This notebook implements YOLOv8 for Ground Penetrating Radar (GPR) hyperbola detection.\n",
        "\n",
        "**Setup Instructions:**\n",
        "- Enable GPU: Runtime → Change runtime type → Hardware accelerator → GPU\n",
        "- Uses Colab's built-in PyTorch (no torch install needed)\n",
        "- Pipeline: dataset → conversion → train → evaluate mAP → predict & visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU info (optional)\n",
        "!nvidia-smi | cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "!pip -q install ultralytics opencv-python numpy tqdm matplotlib\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "print(\"Ultralytics ready. Torch:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get dataset\n",
        "!mkdir -p /content/data\n",
        "!test -d /content/data/gpr-data-classifier || git clone https://github.com/irenexychen/gpr-data-classifier /content/data/gpr-data-classifier\n",
        "!ls -la /content/data/gpr-data-classifier | head -n 40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Convert Dataset from VOC to YOLO Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert VOC XMLs to YOLO and create dataset YAML\n",
        "import os, random, shutil, xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "\n",
        "def read_label_map(label_map_path: Path):\n",
        "    if not label_map_path.exists():\n",
        "        return [\"hyperbola\"]\n",
        "    text = label_map_path.read_text()\n",
        "    names = []\n",
        "    for line in text.splitlines():\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"name:\"):\n",
        "            names.append(line.split(\":\", 1)[1].strip().strip('\\'\"\\''))\n",
        "    return names or [\"hyperbola\"]\n",
        "\n",
        "def convert_voc_box_to_yolo(bbox, img_w, img_h):\n",
        "    xmin, ymin, xmax, ymax = bbox\n",
        "    xmin = max(0, xmin - 1); ymin = max(0, ymin - 1)\n",
        "    xmax = min(img_w - 1, xmax - 1); ymax = min(img_h - 1, ymax - 1)\n",
        "    bw = xmax - xmin; bh = ymax - ymin\n",
        "    cx = xmin + bw / 2.0; cy = ymin + bh / 2.0\n",
        "    return (cx / img_w if img_w > 0 else 0.0,\n",
        "            cy / img_h if img_h > 0 else 0.0,\n",
        "            bw / img_w if img_w > 0 else 0.0,\n",
        "            bh / img_h if img_h > 0 else 0.0)\n",
        "\n",
        "def parse_voc_xml(xml_path: Path):\n",
        "    root = ET.parse(str(xml_path)).getroot()\n",
        "    size = root.find(\"size\")\n",
        "    img_w = int(size.find(\"width\").text); img_h = int(size.find(\"height\").text)\n",
        "    objects = []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        name = obj.find(\"name\").text\n",
        "        bnd = obj.find(\"bndbox\")\n",
        "        xmin = int(float(bnd.find(\"xmin\").text))\n",
        "        ymin = int(float(bnd.find(\"ymin\").text))\n",
        "        xmax = int(float(bnd.find(\"xmax\").text))\n",
        "        ymax = int(float(bnd.find(\"ymax\").text))\n",
        "        objects.append((name, (xmin, ymin, xmax, ymax)))\n",
        "    return img_w, img_h, objects\n",
        "\n",
        "def ensure_dirs(paths):\n",
        "    for p in paths: Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def write_dataset_yaml(output_root: Path, dataset_name: str, names: list):\n",
        "    yaml_path = output_root / f\"{dataset_name}.yaml\"\n",
        "    yaml_path.write_text(\n",
        "        f\"path: {output_root}\\ntrain: images/train\\nval: images/val\\nnames: {names}\\n\"\n",
        "    )\n",
        "    return yaml_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_dataset(source_root, output_root, val_split=0.2, seed=42, dataset_name=\"gpr\"):\n",
        "    random.seed(seed)\n",
        "    source_root = Path(source_root)\n",
        "    images_dir = source_root / \"images\"\n",
        "    xml_dir = source_root / \"annotations\" / \"xmls\"\n",
        "    label_map_path = source_root / \"annotations\" / \"label_map.pbtxt\"\n",
        "\n",
        "    assert images_dir.exists() and xml_dir.exists(), f\"Missing {images_dir} or {xml_dir}\"\n",
        "    class_names = read_label_map(label_map_path)\n",
        "    name_to_id = {n: i for i, n in enumerate(class_names)}\n",
        "\n",
        "    output_root = Path(output_root)\n",
        "    images_train = output_root / \"images\" / \"train\"\n",
        "    images_val = output_root / \"images\" / \"val\"\n",
        "    labels_train = output_root / \"labels\" / \"train\"\n",
        "    labels_val = output_root / \"labels\" / \"val\"\n",
        "    ensure_dirs([images_train, images_val, labels_train, labels_val])\n",
        "\n",
        "    xml_files = sorted([p for p in xml_dir.glob(\"*.xml\")])\n",
        "    samples = []\n",
        "    for xml_path in xml_files:\n",
        "        base = xml_path.stem\n",
        "        img_path = None\n",
        "        for ext in (\".jpg\", \".jpeg\", \".png\"):\n",
        "            cand = images_dir / f\"{base}{ext}\"\n",
        "            if cand.exists():\n",
        "                img_path = cand; break\n",
        "        if img_path is None:\n",
        "            try:\n",
        "                filename_node = ET.parse(str(xml_path)).getroot().find(\"filename\")\n",
        "                if filename_node is not None:\n",
        "                    cand = images_dir / filename_node.text\n",
        "                    if cand.exists(): img_path = cand\n",
        "            except Exception:\n",
        "                pass\n",
        "        if img_path is not None:\n",
        "            samples.append((img_path, xml_path))\n",
        "\n",
        "    assert len(samples) > 0, \"No image-xml pairs found.\"\n",
        "\n",
        "    random.shuffle(samples)\n",
        "    val_count = max(1, int(len(samples) * val_split))\n",
        "    val_samples = set(samples[:val_count])\n",
        "\n",
        "    def convert_and_copy(sample, subset):\n",
        "        img_path, xml_path = sample\n",
        "        try:\n",
        "            img_w, img_h, objects = parse_voc_xml(xml_path)\n",
        "        except Exception as e:\n",
        "            print(\"Parse error, skip:\", xml_path, e); return\n",
        "        lines = []\n",
        "        for name, bbox in objects:\n",
        "            if name not in name_to_id: continue\n",
        "            cls = name_to_id[name]\n",
        "            x, y, w, h = convert_voc_box_to_yolo(bbox, img_w, img_h)\n",
        "            if w <= 0 or h <= 0: continue\n",
        "            lines.append(f\"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\")\n",
        "        if not lines: return\n",
        "        if subset == \"train\":\n",
        "            dst_img = images_train / img_path.name\n",
        "            dst_lbl = labels_train / (img_path.stem + \".txt\")\n",
        "        else:\n",
        "            dst_img = images_val / img_path.name\n",
        "            dst_lbl = labels_val / (img_path.stem + \".txt\")\n",
        "        shutil.copy2(str(img_path), str(dst_img))\n",
        "        dst_lbl.write_text(\"\\n\".join(lines) + \"\\n\")\n",
        "\n",
        "    for sample in samples:\n",
        "        subset = \"val\" if sample in val_samples else \"train\"\n",
        "        convert_and_copy(sample, subset)\n",
        "\n",
        "    yaml_path = write_dataset_yaml(output_root, dataset_name, class_names)\n",
        "    print(\"Done. YAML at:\", yaml_path)\n",
        "    print(\"Train images:\", len(list(images_train.glob('*'))), \"Val images:\", len(list(images_val.glob('*'))))\n",
        "    return str(yaml_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run conversion\n",
        "data_yaml = convert_dataset(\n",
        "    source_root=\"/content/data/gpr-data-classifier/hyperbola-classifier\",\n",
        "    output_root=\"/content/data/gpr_yolo\",\n",
        "    val_split=0.2, seed=42, dataset_name=\"gpr\"\n",
        ")\n",
        "print(\"Using data yaml:\", data_yaml)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train YOLOv8 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train YOLOv8 (strong settings for T4)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "data_yaml = \"/content/data/gpr_yolo/gpr.yaml\"\n",
        "project = \"/content/Results/yolo_runs\"\n",
        "name = \"gpr_yolov8m_e150_i960_aug\"\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")  # try 'yolov8l.pt' if VRAM permits\n",
        "\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=150,\n",
        "    imgsz=960,\n",
        "    batch=8,\n",
        "    patience=30,\n",
        "    lr0=0.01,\n",
        "    lrf=0.01,\n",
        "    weight_decay=0.0005,\n",
        "    momentum=0.937,\n",
        "    warmup_epochs=3.0,\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0,\n",
        "    flipud=0.0, fliplr=0.5,\n",
        "    mosaic=0.7, mixup=0.1, copy_paste=0.0,\n",
        "    erasing=0.4,\n",
        "    project=project,\n",
        "    name=name,\n",
        ")\n",
        "print(results)\n",
        "\n",
        "best_weights = f\"{project}/{name}/weights/best.pt\"\n",
        "print(\"Best weights:\", best_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate mAP on val\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(best_weights)\n",
        "metrics = model.val(\n",
        "    data=data_yaml,\n",
        "    split=\"val\",\n",
        "    imgsz=960,\n",
        "    batch=8,\n",
        "    conf=0.001,\n",
        "    iou=0.6,\n",
        "    plots=True,\n",
        "    project=\"/content/Results/yolo_val\",\n",
        "    name=\"gpr_eval\"\n",
        ")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"mAP50:    {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP75:    {metrics.box.map75:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Predict and Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict and visualize\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "model = YOLO(best_weights)\n",
        "_ = model.predict(\n",
        "    source=\"/content/data/gpr_yolo/images/val\",\n",
        "    imgsz=960,\n",
        "    save=True,\n",
        "    project=\"/content/Results/yolo_preds\",\n",
        "    name=\"preds\"\n",
        ")\n",
        "\n",
        "pred_imgs = sorted(glob.glob(\"/content/Results/yolo_preds/preds/*.jpg\"))[:12]\n",
        "for p in pred_imgs:\n",
        "    display(Image(filename=p))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}